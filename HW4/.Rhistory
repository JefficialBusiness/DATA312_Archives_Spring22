votes_gop,
votes_dem) %>%
svm(y = P2_query_truth, kernel = 'radial')
P2q_radial_pred <- query %>%
mutate(predicted_RUCC = predict(P2q_svm_radial, query %>% select(TOT_POP,
gopPercent,
demPercent,
black,
white,
hispanic,
votes_gop,
votes_dem)))
P2q_radial_scores <- P2q_radial_pred %>%
mutate(correct_guess = (predicted_RUCC ==
Rural_urban_continuum_code_2013)) %>%
count(PostalCode, correct_guess)
P2q_radial_scores %>% mutate(PostalCode = reorder(PostalCode, desc(n))) %>%
ggplot(aes(n, PostalCode, fill = correct_guess)) + geom_col() +
labs(title = "Predicting Rural-Urban Continuum Code (Radial SVM)")
# Radial SVM Test
P2t_svm_radial <- P2_test_input %>% select(TOT_POP,
gopPercent,
demPercent,
black,
white,
hispanic,
votes_gop,
votes_dem) %>%
svm(y = P2_test_truth, kernel = 'radial')
P2t_radial_pred <- test %>%
mutate(predicted_RUCC = predict(P2t_svm_radial, test %>% select(TOT_POP,
gopPercent,
demPercent,
black,
white,
hispanic,
votes_gop,
votes_dem)))
P2t_radial_scores <- P2t_radial_pred %>%
mutate(correct_guess = (predicted_RUCC ==
Rural_urban_continuum_code_2013)) %>%
count(PostalCode, correct_guess)
P2t_radial_scores %>% mutate(PostalCode = reorder(PostalCode, desc(n))) %>%
ggplot(aes(n, PostalCode, fill = correct_guess)) + geom_col() +
labs(title = "Predicting Rural-Urban
Continuum Code (Radial SVM)")
plot_usmap(regions = 'counties', data = temporary, values = 'hispanic',
include = c('CA', 'IL', 'MD', 'GA'))
plot_usmap(regions = 'counties', data = temporary, values = 'hispanic',
include = c('IL', 'MD', 'GA'))
plot_usmap(regions = 'counties', data = temporary, values = 'black',
include = c('IL', 'MD', 'GA'))
plot_usmap(regions = 'counties', data = temporary, values = 'black',
include = c('MD', 'VA', 'DC', 'PA', 'NJ', 'NY'))
plot_usmap(regions = 'counties', data = temporary, values = 'black',
include = c('CA'))
plot_usmap(regions = 'counties', data = temporary, values = 'black',
include = c('CA', 'GA'))
plot_usmap(regions = 'counties', data = temporary, values = 'black',
include = c('GA', 'FL'))
plot_usmap(regions = 'counties', data = temporary, values = 'white',
include = c('GA', 'FL'))
plot_usmap(regions = 'counties', data = temporary, values = 'white',
include = c('GA', 'FL','IL'))
plot_usmap(regions = 'counties', data = temporary, values = 'white',
include = c('GA', 'FL'))
plot_usmap(regions = 'counties', data = temporary, values = 'CDPerThou.04.2021',
include = c('GA', 'FL'))
plot_usmap(regions = 'counties', data = temporary, values = 'CDPerThou.04.2021',
include = c('IL'))
plot_usmap(regions = 'counties', data = temporary, values = 'CDPerThou.04.2021',
include = c('IL', 'IN', 'MI'))
plot_usmap(regions = 'counties', data = temporary, values = 'CDPerThou.04.2021',
include = c('IL', 'IN', 'MI'))
rm(list=ls())
gc()
library(tidyverse)
library(modelr)
library(e1071)
library(usmap)
megadata <- read_csv('EduUnempPovPopCovidVoting_StatCrunchV2.csv')
temporary <- megadata %>% mutate(fips = countyFIPS)
# Cleaning / Sorting quantitative from categorical variables
megadata <- megadata %>% mutate(countyFIPS = as.factor(countyFIPS)) %>%
mutate(StateFIPS = as.factor(StateFIPS)) %>%
mutate(FIPSnumber = as.factor(FIPSnumber)) %>%
mutate(Rural.urban_Continuum_Code_2003 =
as.factor(Rural.urban_Continuum_Code_2003)) %>%
mutate(Rural_urban_continuum_code_2013 =
as.factor(Rural_urban_continuum_code_2013)) %>%
mutate(PoliticsGroup = as.factor(PoliticsGroup))
raw_data_samplingframe <- megadata %>% mutate(snum = sample.int(n(), n()) / n())
training <- raw_data_samplingframe %>% filter(snum < 0.6) %>% select(-snum)
query <- raw_data_samplingframe %>% filter(snum >= 0.6, snum < 0.8) %>%
select(-snum)
test <- raw_data_samplingframe %>% filter(snum >= 0.8) %>% select(-snum)
# Gathering quantitative variables
quantitatives <- training %>% select(where(is.numeric))
categoricals <- training %>% select(where(is.factor))
training_pca <- quantitatives %>% prcomp()
query_P1 <- query %>%
add_predictions(lfit, var = 'P1q_lfit_pred') %>%
add_residuals(lfit, var = 'P1q_lfit_resid') %>%
add_predictions(polyfit, var = 'P1q_polyfit_pred') %>%
add_residuals(polyfit, var = 'P1q_polyfit_resid')
training %>%
ggplot(aes(hispanic, CDPerThou.04.2021)) +
geom_point() +
labs(title = 'County Hispanic Population vs. COVID Death Rate by April 2021')
quantitatives <- training %>% select(where(is.numeric))
categoricals <- training %>% select(where(is.factor))
training_pca <- quantitatives %>% prcomp()
training_pca$x %>% as_tibble() %>%
mutate(PostalCode=training$PostalCode) %>%
ggplot(aes(PC1, PC2, color = PostalCode)) + geom_point()
training_pca$x %>% as_tibble() %>%
mutate(Rural_urban_continuum_code_2013=training$Rural_urban_continuum_code_2013) %>%
ggplot(aes(PC1, PC2, color = Rural_urban_continuum_code_2013)) + geom_point()
lfit <- lm(CDPerThou.04.2021~hispanic, data = training)
polyfit <-lm(CDPerThou.04.2021~poly(hispanic, 2), data = training)
# Training lfit model
training_lfit_P1 <- training %>%
add_predictions(lfit, var = 'P1tr_lfit_pred') %>%
add_residuals(lfit, var = 'P1tr_lfit_resid')
training_lfit_P1 %>%
ggplot(aes(hispanic, CDPerThou.04.2021)) +
geom_point() + geom_line(aes(hispanic, P1tr_lfit_pred), color = 'blue') +
labs(title = 'Predicting Trends in Hispanic COVID Death Rate by April 2021
(Linear Regression Model)')
# -- Problem 2 --
P2_training_input <- training %>% select(-Rural_urban_continuum_code_2013)
P2_training_truth <- training$Rural_urban_continuum_code_2013
P2_query_input <- query %>% select(-Rural_urban_continuum_code_2013)
P2_query_truth <- query$Rural_urban_continuum_code_2013
P2_test_input <- test %>% select(-Rural_urban_continuum_code_2013)
P2_test_truth <- test$Rural_urban_continuum_code_2013
# Training
# Linear SVM
P2tr_svm_linear <- P2_training_input %>% select(TOT_POP,
gopPercent,
demPercent,
black,
white,
hispanic,
votes_gop,
votes_dem) %>%
svm(y = P2_training_truth, kernel = 'linear')
P2tr_linear_pred <- training %>%
mutate(predicted_RUCC = predict(P2tr_svm_linear, training %>% select(TOT_POP,
gopPercent,
demPercent,
black,
white,
hispanic,
votes_gop,
votes_dem)))
P2tr_linear_scores <- P2tr_linear_pred %>%
mutate(correct_guess = (predicted_RUCC ==
Rural_urban_continuum_code_2013)) %>%
count(PostalCode, correct_guess)
P2tr_linear_scores %>% mutate(PostalCode = reorder(PostalCode, desc(n))) %>%
ggplot(aes(n, PostalCode, fill = correct_guess)) + geom_col() +
labs(title = "Predicting Rural-Urban
Continuum Code (Polynomial SVM)")
# Radial SVM
P2tr_svm_radial <- P2_training_input %>% select(TOT_POP,
gopPercent,
demPercent,
black,
white,
hispanic,
votes_gop,
votes_dem) %>%
svm(y = P2_training_truth, kernel = 'radial')
P2tr_radial_pred <- training %>%
mutate(predicted_RUCC = predict(P2tr_svm_radial, training %>% select(TOT_POP,
gopPercent,
demPercent,
black,
white,
hispanic,
votes_gop,
votes_dem)))
P2tr_radial_scores <- P2tr_radial_pred %>%
mutate(correct_guess = (predicted_RUCC ==
Rural_urban_continuum_code_2013)) %>%
count(PostalCode, correct_guess)
P2tr_radial_scores %>% mutate(PostalCode = reorder(PostalCode, desc(n))) %>%
ggplot(aes(n, PostalCode, fill = correct_guess)) + geom_col() +
labs(title = "Predicting Rural-Urban
Continuum Code (Radial SVM)")
plot_usmap(regions = 'counties', data = temporary, values = 'CDPerThou.04.2021',
include = c('IL', 'IN', 'MI')) +
theme(legend.position = "right")
plot_usmap(regions = 'counties', data = temporary, values = 'white',
include = c('GA', 'FL')) +
theme(legend.position = "right")
training %>%
ggplot(aes(demPercent, Rural_urban_continuum_code_2013, color = black)) + geom_point() +
labs(title = 'GOP Pop. vs. White Pop. vs. RUCC (2013)')
# Clearing Workspace / Loading libraries
rm(list = ls())
gc()
library(tidyverse)
library(dplyr)
library(e1071)
library(stevedata) # For my dataset
data("spam", package = 'kernlab')
raw_data_samplingframe <- spam %>% select(-george, -num650) %>%
mutate(snum = sample.int(n(), n()) / n())
training <- raw_data_samplingframe %>% filter(snum < 0.6) %>% select(-snum)
query <- raw_data_samplingframe %>% filter(snum >= 0.6, snum < 0.8) %>%
select(-snum)
test <- raw_data_samplingframe %>% filter(snum > 0.8) %>% select(-snum)
training %>% write_csv('spam_training.csv')
query %>% write_csv('spam_query.csv')
test %>% write_csv('spam_test.csv')
training_input <- training %>% select(-type)
training_truth <- training$type
query_input <- query %>% select(-type)
query_truth <- query$type
test_input <- test %>% select(-type)
test_truth <- test$type
# Training
spam_pca <- training_input %>% prcomp()
spam_pca$x %>% as_tibble() %>% mutate(type = training_truth) %>%
ggplot(aes(PC1, PC2, color = type)) + geom_point()
# Attempting k-means analysis
spam_kmeans <- training_input %>% kmeans(2)
kmeans_results <- tibble(training_truth, km = spam_kmeans$cluster)
kmeans_results %>% count(training_truth, km) %>%
pivot_wider(names_from = km, values_from = n)
ct <- kmeans_results %>% count(training_truth, km) %>%
pivot_wider(names_from = km, values_from = n) %>%
column_to_rownames('training_truth')
chisq.test(ct)
spam_pca$x %>% as_tibble() %>%
ggplot(aes(PC1, PC2, color = spam_kmeans$cluster)) + geom_point()
# Trying SVM training
svm_linear <- training_input %>% svm(y = training_truth, kernel = 'linear')
svm_poly <- training_input %>% svm(y = training_truth, kernel = 'polynomial')
svm_radial <- training_input %>% svm(y = training_truth, kernel = 'radial')
svm_sigmoid <- training_input %>% svm(y = training_truth, kernel = 'sigmoid')
training_pca <- spam_pca$x %>% as_tibble() %>% mutate(type = training_truth)
sl <- svm(type~., data = training_pca, kernel = 'linear')
sp <- svm(type~., data = training_pca, kernel = 'polynomial')
sr <- svm(type~., data = training_pca, kernel = 'radial')
ss <- svm(type~., data = training_pca, kernel = 'sigmoid')
plot(sl, training_pca, PC1~PC2)
plot(sp, training_pca, PC1~PC2)
plot(sr, training_pca, PC1~PC2)
plot(ss, training_pca, PC1~PC2)
# SVM Query
predict(svm_linear, query_input)
query_results <- tibble(query_truth,
linear = predict(svm_linear, query_input),
poly = predict(svm_poly, query_input),
radial = predict(svm_radial, query_input),
sigmoid = predict(svm_sigmoid, query_input))
query_results1 <- query_results %>% pivot_longer(cols=!query_truth)
query_results2 <- query_results1 %>%
mutate(tp = (query_truth == 'spam' & value == 'spam'),
tn = (query_truth == 'nonspam' & value == 'nonspam'),
fp = (query_truth == 'nonspam' & value == 'spam'),
fn = (query_truth == 'spam' & value == 'nonspam'))
query_results3 <- query_results2 %>% group_by(name) %>%
summarize(tp = sum(tp),
tn = sum(tn),
fp = sum(fp),
fn = sum(fn))
query_results3 %>% mutate(accuracy = (tp + tn) / (tp + tn + fp + fn),
sensitivity = tp / (tp + fn),
specificity = tn / (tn + fp),
ppv = tp / (tp + fp),
npv = fn / (tn + fn),
f1 = (2 * tp) / (2 * tp + fp + fn))
data("TV16", package = "stevedata")
my_samplingframe <- TV16 %>% select(-state, -age, -female, -collegeed, -racef,
-bornagain)
# Clearing Workspace / Loading libraries
rm(list = ls())
gc()
library(tidyverse)
library(dplyr)
library(e1071)
library(stevedata) # For my dataset
data("TV16", package = "stevedata")
my_samplingframe <- TV16 %>% select(-state, -age, -female, -collegeed, -racef,
-bornagain)
my_samplingframe <- na.omit(my_samplingframe) %>%
mutate(snum = sample.int(n(), n()) / n())
my_training <- my_samplingframe %>% filter(snum < 0.06*2) %>% select(-snum)
my_query <- my_samplingframe %>% filter(snum >= 0.06*2, snum < 0.08*2) %>%
select(-snum)
# Separating Correct Answer / Identifying Variable
my_tr_input <- my_training %>% select(-votetrump)
my_tr_truth <- my_training$votetrump %>% as.factor()
my_q_input <- my_query %>% select(-votetrump)
my_q_truth <- my_query$votetrump %>% as.factor()
my_t_input <- my_test %>% select(-votetrump)
my_test <- my_samplingframe %>% filter(snum >= 0.08*2) %>% select(-snum)
my_t_input <- my_test %>% select(-votetrump)
my_t_truth <- my_test$votetrump %>% as.factor()
# SVM Training
trump_pca <- my_tr_input %>% prcomp()
trump_pca$x %>% as_tibble() %>% mutate(votetrump = my_tr_truth) %>%
ggplot(aes(PC1, PC2, color = votetrump)) + geom_point()
# Trying SVM training against data
my_slinear <- my_tr_input %>% svm(y = my_tr_truth, kernel = 'linear')
my_spoly <- my_tr_input %>% svm(y = my_tr_truth, kernel = 'polynomial')
my_sradial <- my_tr_input %>% svm(y = my_tr_truth, kernel = 'radial')
my_ssigmoid <- my_tr_input %>% svm(y = my_tr_truth, kernel = 'sigmoid')
my_tr_pca <- trump_pca$x %>% as_tibble() %>% mutate(votetrump = my_tr_truth)
# Training SVM against data after PCA transformation
my_sl <- svm(votetrump~., data = my_tr_pca, kernel = 'linear')
my_sp <- svm(votetrump~., data = my_tr_pca, kernel = 'polynomial')
my_sr <- svm(votetrump~., data = my_tr_pca, kernel = 'radial')
my_ss <- svm(votetrump~., data = my_tr_pca, kernel = 'sigmoid')
plot(my_sl, my_tr_pca, PC1~PC2)
my_q_results <- tibble(my_q_truth,
my_sl_pred = predict(my_slinear, my_q_input),
my_sr_pred = predict(my_sradial, my_q_input),
my_ss_pred = predict(my_ssigmoid, my_q_input))
my_q_results1 <- my_q_results %>% pivot_longer(cols=!my_q_truth)
my_q_results2 <- my_q_results1 %>%
mutate(my_tp = (my_q_truth == '1' & value == '1'),
my_tn = (my_q_truth == '0' & value == '0'),
my_fp = (my_q_truth == '0' & value == '1'),
my_fn = (my_q_truth == '1' & value == '0'))
my_q_results3 <- my_q_results2 %>% group_by(name) %>%
summarize(my_tp = sum(my_tp),
my_tn = sum(my_tn),
my_fp = sum(my_fp),
my_fn = sum(my_fn))
my_q_results3 %>% mutate(my_accuracy =
(my_tp + my_tn) / (my_tp + my_tn + my_fp + my_fn),
my_sensitivity = my_tp / (my_tp + my_fn),
my_specificity = my_tn / (my_tn + my_fp),
my_ppv = my_tp / (my_tp + my_fp),
my_npv = my_fn / (my_tn + my_fn),
my_f1 = (2 * my_tp) / (2 * my_tp + my_fp + my_fn))
my_t_results <- tibble(my_t_truth,
my_sr_pred = predict(my_sradial, my_t_input))
my_t_results1 <- my_t_results %>% pivot_longer(cols=!my_t_truth)
my_t_results2 <- my_t_results1 %>%
mutate(my_tp = (my_t_truth == '1' & value == '1'),
my_tn = (my_t_truth == '0' & value == '0'),
my_fp = (my_t_truth == '0' & value == '1'),
my_fn = (my_t_truth == '1' & value == '0'))
my_t_results3 <- my_t_results2 %>% group_by(name) %>%
summarize(my_tp = sum(my_tp),
my_tn = sum(my_tn),
my_fp = sum(my_fp),
my_fn = sum(my_fn))
my_t_results3 %>% mutate(my_accuracy =
(my_tp + my_tn) / (my_tp + my_tn + my_fp + my_fn),
my_sensitivity = my_tp / (my_tp + my_fn),
my_specificity = my_tn / (my_tn + my_fp),
my_ppv = my_tp / (my_tp + my_fp),
my_npv = my_fn / (my_tn + my_fn),
my_f1 = (2 * my_tp) / (2 * my_tp + my_fp + my_fn))
# Observations: My test results for the radial model appear to be similar, with
# Observations: My test results for the radial model appear to be similar, with
# an f1 score of 86% and an accuracy score of 89%. Notably, sensitivity and
# Observations: My test results for the radial model appear to be similar, with
# an f1 score of 86% and an accuracy score of 89%. Notably, sensitivity and
# specificity scores are lower by a considerable margin, compared to the query
# Observations: My test results for the radial model appear to be similar, with
# an f1 score of 86% and an accuracy score of 89%. Notably, sensitivity and
# specificity scores are lower by a considerable margin, compared to the query
# results. The f1 score for the radial model test result is, moreover, lower
# Observations: My test results for the radial model appear to be similar, with
# an f1 score of 86% and an accuracy score of 89%. Notably, sensitivity and
# specificity scores are lower by a considerable margin, compared to the query
# results. The f1 score for the radial model test result is, moreover, lower
# than the f1 score for the linear model query result by .002, piquing further
# Observations: My test results for the radial model appear to be similar, with
# an f1 score of 86% and an accuracy score of 89%. Notably, sensitivity and
# specificity scores are lower by a considerable margin, compared to the query
# results. The f1 score for the radial model test result is, moreover, lower
# than the f1 score for the linear model query result by .002, piquing further
# curiosity, in that it begs further investigation as to how both models are
# Observations: My test results for the radial model appear to be similar, with
# an f1 score of 86% and an accuracy score of 89%. Notably, sensitivity and
# specificity scores are lower by a considerable margin, compared to the query
# results. The f1 score for the radial model test result is, moreover, lower
# than the f1 score for the linear model query result by .002, piquing further
# curiosity, in that it begs further investigation as to how both models are
# different, and whether one truly performs better than the other. While the
my_t_results3 %>% mutate(accuracy =
(tp + my_tn) / (tp + tn + fp + fn),
sensitivity = tp / (tp + fn),
specificity = tn / (tn + fp),
ppv = tp / (tp + fp),
npv = fn / (tn + fn),
f1 = (2 * tp) / (2 * tp + fp + fn))
my_t_results3 <- my_t_results2 %>% group_by(name) %>%
summarize(my_tp = sum(my_tp),
my_tn = sum(my_tn),
my_fp = sum(my_fp),
my_fn = sum(my_fn))
my_t_results3 %>% mutate(accuracy =
(tp + my_tn) / (tp + tn + fp + fn),
sensitivity = tp / (tp + fn),
specificity = tn / (tn + fp),
ppv = tp / (tp + fp),
npv = fn / (tn + fn),
f1 = (2 * tp) / (2 * tp + fp + fn))
# Clearing Workspace / Loading libraries
rm(list = ls())
gc()
library(tidyverse)
library(dplyr)
library(e1071)
library(stevedata) # For my dataset
data("spam", package = 'kernlab')
raw_data_samplingframe <- spam %>% select(-george, -num650) %>%
mutate(snum = sample.int(n(), n()) / n())
training <- raw_data_samplingframe %>% filter(snum < 0.6) %>% select(-snum)
query <- raw_data_samplingframe %>% filter(snum >= 0.6, snum < 0.8) %>%
select(-snum)
test <- raw_data_samplingframe %>% filter(snum > 0.8) %>% select(-snum)
training %>% write_csv('spam_training.csv')
query %>% write_csv('spam_query.csv')
test %>% write_csv('spam_test.csv')
training_input <- training %>% select(-type)
training_truth <- training$type
query_input <- query %>% select(-type)
query_truth <- query$type
test_input <- test %>% select(-type)
test_truth <- test$type
# Training
spam_pca <- training_input %>% prcomp()
spam_pca$x %>% as_tibble() %>% mutate(type = training_truth) %>%
ggplot(aes(PC1, PC2, color = type)) + geom_point()
# Attempting k-means analysis
spam_kmeans <- training_input %>% kmeans(2)
kmeans_results <- tibble(training_truth, km = spam_kmeans$cluster)
kmeans_results %>% count(training_truth, km) %>%
pivot_wider(names_from = km, values_from = n)
ct <- kmeans_results %>% count(training_truth, km) %>%
pivot_wider(names_from = km, values_from = n) %>%
column_to_rownames('training_truth')
chisq.test(ct)
spam_pca$x %>% as_tibble() %>%
ggplot(aes(PC1, PC2, color = spam_kmeans$cluster)) + geom_point()
# Trying SVM training
svm_linear <- training_input %>% svm(y = training_truth, kernel = 'linear')
svm_poly <- training_input %>% svm(y = training_truth, kernel = 'polynomial')
svm_radial <- training_input %>% svm(y = training_truth, kernel = 'radial')
svm_sigmoid <- training_input %>% svm(y = training_truth, kernel = 'sigmoid')
training_pca <- spam_pca$x %>% as_tibble() %>% mutate(type = training_truth)
sl <- svm(type~., data = training_pca, kernel = 'linear')
sp <- svm(type~., data = training_pca, kernel = 'polynomial')
sr <- svm(type~., data = training_pca, kernel = 'radial')
ss <- svm(type~., data = training_pca, kernel = 'sigmoid')
# SVM Query
predict(svm_linear, query_input)
query_results <- tibble(query_truth,
linear = predict(svm_linear, query_input),
poly = predict(svm_poly, query_input),
radial = predict(svm_radial, query_input),
sigmoid = predict(svm_sigmoid, query_input))
query_results1 <- query_results %>% pivot_longer(cols=!query_truth)
query_results2 <- query_results1 %>%
mutate(tp = (query_truth == 'spam' & value == 'spam'),
tn = (query_truth == 'nonspam' & value == 'nonspam'),
fp = (query_truth == 'nonspam' & value == 'spam'),
fn = (query_truth == 'spam' & value == 'nonspam'))
query_results3 <- query_results2 %>% group_by(name) %>%
summarize(tp = sum(tp),
tn = sum(tn),
fp = sum(fp),
fn = sum(fn))
query_results3 %>% mutate(accuracy = (tp + tn) / (tp + tn + fp + fn),
sensitivity = tp / (tp + fn),
specificity = tn / (tn + fp),
ppv = tp / (tp + fp),
npv = fn / (tn + fn),
f1 = (2 * tp) / (2 * tp + fp + fn))
# SVM Test
test_results <- tibble(test_truth,
linear = predict(svm_linear, test_input))
test_results1 <- test_results %>% pivot_longer(cols=!test_truth)
test_results2 <- test_results1 %>%
mutate(tp = (test_truth == 'spam' & value == 'spam'),
tn = (test_truth == 'nonspam' & value == 'nonspam'),
fp = (test_truth == 'nonspam' & value == 'spam'),
fn = (test_truth == 'spam' & value == 'nonspam'))
test_results3 <- test_results2 %>% group_by(name) %>%
summarize(tp = sum(tp),
tn = sum(tn),
fp = sum(fp),
fn = sum(fn))
test_results3 %>% mutate(accuracy = (tp + tn) / (tp + tn + fp + fn),
sensitivity = tp / (tp + fn),
specificity = tn / (tn + fp),
ppv = tp / (tp + fp),
npv = fn / (tn + fn),
f1 = (2 * tp) / (2 * tp + fp + fn))
data("TV16", package = "stevedata")
my_samplingframe <- TV16 %>% select(-state, -age, -female, -collegeed, -racef,
-bornagain)
my_samplingframe <- na.omit(my_samplingframe) %>%
mutate(snum = sample.int(n(), n()) / n())
my_training <- my_samplingframe %>% filter(snum < 0.06*2) %>% select(-snum)
my_query <- my_samplingframe %>% filter(snum >= 0.06*2, snum < 0.08*2) %>%
select(-snum)
my_test <- my_samplingframe %>% filter(snum >= 0.08*2) %>% select(-snum)
my_training %>% write_csv('HW4B_training.csv')
my_query %>% write_csv('HW4B_query.csv')
my_test %>% write_csv('HW4B_test.csv')
