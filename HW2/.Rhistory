# Cleaning workspace / loading libraries
rm(list=ls())
gc()
library(tidyverse)
library(tidytext)
library(gutenbergr)
library(textdata)
library(wordcloud)
library(reshape2)
library(wordcloud)
shakespeare_corpus <- read_csv('shakespeare_gutenberg.csv')
View(shakespeare_corpus)
eme_stop_words <- tibble(word=c("thee", "thou", "hath", "thy", "thine", "ye",
"tis"))
book <- gutenberg_download(shakespeare_corpus$'Gutenberg ID'[1])
book <- book %>%
add_row(gutenberg_download(shakespeare_corpus$'Gutenberg ID'[2]))
for(i in 3:nrow(shakespeare_corpus)) {
book <- book %>%
add_row(gutenberg_download(shakespeare_corpus$'Gutenberg ID'[i]))
}
shakespeare_corpus <- read_csv('shakespeare_gutenberg.csv')
# Load Libraries
library(tidyverse)
library(gutenbergr)
library(tidytext)
dickens_list <- read_csv('dickens_gutenberg.csv')
mirror <- 'http://gutenberg.readingroo.ms/'
book <- gutenberg_download(dickens_list$'Gutenberg ID'[1], mirror = mirror)
for(i in 2:nrow(dickens_list)) {
book <- book %>% add_row(gutenberg_download(dickens_list$`Gutenberg ID`[i],
mirror = mirror))
}
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID"))
total_words <- tidy_dickens %>% group_by(Name) %>% summarize(total=sum(n))
# Retrieving / applying associated sentiments of words using "bing" lexicon
bing_sentiments <- get_sentiments("bing")
tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Type) %>%
count(sentiment)
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID"))
total_words <- tidy_dickens %>% group_by(Name) %>% summarize(total=sum(n))
View(total_words)
# Retrieving / applying associated sentiments of words using "bing" lexicon
bing_sentiments <- get_sentiments("bing")
tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Type) %>%
count(sentiment)
tidy_dickens %>% inner_join(bing_sentiments) %>%
count(sentiment)
View(tidy_dickens)
View(total_words)
View(tidy_dickens)
tidy_dickens %>% inner_join(bing_sentiments) %>%
count(sentiment)
View(bing_sentiments)
View(tidy_dickens)
tidy_dickens %>% inner_join(bing_sentiments) %>%
count(sentiment)
# Graphical analysis of gathered sentiment information
tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Type) %>%
count(sentiment) %>% ggplot(aes(Type, n, fill=sentiment)) +
geom_col(position='dodge')
tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment)
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID"))
total_words <- tidy_dickens %>% group_by(Name) %>% summarize(total=sum(n))
# Retrieving / applying associated sentiments of words using "bing" lexicon
bing_sentiments <- get_sentiments("bing")
tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment)
tidy_dickens %>% inner_join(bing_sentiments)
View(dickens_list)
View(dickens_list)
View(tidy_dickens)
tidy_dickens %>% inner_join(bing_sentiments)
View(tidy_dickens)
tidy_dickens <- tidy_dickens %>% inner_join(bing_sentiments)
View(tidy_dickens)
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID"))
tidy_dickens %>% inner_join(bing_sentiments)
tidy_dickens <- tidy_dickens %>% inner_join(bing_sentiments)
# Graphical analysis of gathered sentiment information
tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% ggplot(aes(Type, n, fill=sentiment)) +
geom_col(position='dodge')
# Graphical analysis of gathered sentiment information
tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')
# Graphical analysis of gathered sentiment information
tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word Count")
tidy_dickens <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name)
# Graphical analysis of gathered sentiment information
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word Count")
# Contingency table on sentiment information - widening for multi. relationships
ct <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
View(ct)
# Load Libraries
library(tidyverse)
library(gutenbergr)
library(tidytext)
dickens_list <- read_csv('dickens_gutenberg.csv')
mirror <- 'http://gutenberg.readingroo.ms/'
book <- gutenberg_download(dickens_list$'Gutenberg ID'[1], mirror = mirror)
for(i in 2:nrow(dickens_list)) {
book <- book %>% add_row(gutenberg_download(dickens_list$`Gutenberg ID`[i],
mirror = mirror))
}
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID"))
total_words <- tidy_dickens %>% group_by(Name) %>% summarize(total=sum(n))
# Sentiment Analysis - Bing
bing_sentiments <- get_sentiments("bing")
tidy_dickens <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name)
# Chi-sq test
chSq <- chisq.test(ct)
View(ct)
View(chSq)
chSq
# Analysis of chi-square test - expected values and implications regarding
# relationships
chSq$observed
chSq$expected
chSq$stdres
# Pivoting to the use of "afinn" lexicon to determine sentiment by word weight
afinn_sentiments <- get_sentiments("afinn")
tidy_dickens_afinn <- tidy_dickens %>%
inner_join(afinn_sentiments) %>% inner_join(bing_sentiments)
tidy_dickens_afinn %>% group_by(Name) %>%
summarize(value = mean(value))
View(tidy_dickens_afinn)
tidy_dickens_afinn %>% ggplot(aes(Name, value)) + geom_violin()
tidy_dickens_afinn %>% ggplot(aes(Name, value)) + geom_point()
tidy_dickens_afinn %>% ggplot(aes(Name, value)) + geom_boxplot()
tidy_dickens_afinn %>% ggplot(aes(Name, value)) + geom_dotplot()
tidy_dickens_afinn %>% ggplot(aes(Name, value)) + geom_linerange()
tidy_dickens_afinn %>% ggplot(aes(Name, value)) + geom_vline()
tidy_dickens_afinn %>% ggplot(aes(Name, value)) + geom_area()
tidy_dickens_afinn %>% ggplot(aes(Name, value)) + geom_col()
tidy_dickens_afinn %>% ggplot(aes(Name, value)) + geom_violin()
# Graphs
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word Count")
# Contingency table
ct <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID")) %>%
anti_join(stop_words)
total_words <- tidy_dickens %>% group_by(Name) %>% summarize(total=sum(n))
# Sentiment Analysis - Bing
bing_sentiments <- get_sentiments("bing")
tidy_dickens <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name)
# Graphs
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word Count")
source("~/DATA312/HW2/HW2C.R")
# Load Libraries
library(tidyverse)
library(gutenbergr)
library(tidytext)
dickens_list <- read_csv('dickens_gutenberg.csv')
View(dickens_list)
book <- gutenberg_download(dickens_list$'Gutenberg ID'[1])
for(i in 2:nrow(dickens_list)) {
book <- book %>% add_row(gutenberg_download(dickens_list$`Gutenberg ID`[i]))
}
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID")) %>%
anti_join(stop_words)
total_words <- tidy_dickens %>% group_by(Name) %>% summarize(total=sum(n))
# Sentiment Analysis - Bing
bing_sentiments <- get_sentiments("bing")
tidy_dickens <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name)
# Graphs
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word Count")
# Graphs
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word =")
rm(list=ls())
gc()
rm(list=ls())
gc()
rm(list=ls())
gc()
rm(list=ls())
gc()
rm(list=ls())
gc()
rm(list=ls())
gc()
rm(list=ls())
gc()
rm(list=ls())
gc()
# Graphs
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word Count")
dickens_list <- read_csv('dickens_gutenberg.csv')
mirror <- 'http://gutenberg.readingroo.ms/'
book <- gutenberg_download(dickens_list$'Gutenberg ID'[1], mirror = mirror)
for(i in 2:nrow(dickens_list)) {
book <- book %>% add_row(gutenberg_download(dickens_list$`Gutenberg ID`[i],
mirror = mirror))
}
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID")) %>%
anti_join(stop_words)
total_words <- tidy_dickens %>% group_by(Name) %>% summarize(total=sum(n))
# Sentiment Analysis - Bing
bing_sentiments <- get_sentiments("bing")
tidy_dickens <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name)
# Graphs
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word Count")
# Contingency table
ct <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
# Chi-sq test
chSq <- chisq.test(ct)
View(bing_sentiments)
chSq
chSq$observed
# Contingency table
ct <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
# Chi-sq test
chSq <- chisq.test(ct)
View(ct)
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID"))
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID"))
total_words <- tidy_dickens %>% group_by(Name) %>% summarize(total=sum(n))
# Sentiment Analysis - Bing
bing_sentiments <- get_sentiments("bing")
tidy_dickens <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name)
# Graphs
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word Count")
# Contingency table
ct <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
# Graphs
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word Count")
# Contingency table
ct <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
