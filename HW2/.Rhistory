for(i in 2:nrow(dickens_list)) {
book <- book %>% add_row(gutenberg_download(dickens_list$`Gutenberg ID`[i]))
}
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID")) %>%
anti_join(stop_words)
total_words <- tidy_dickens %>% group_by(Name) %>% summarize(total=sum(n))
# Sentiment Analysis - Bing
bing_sentiments <- get_sentiments("bing")
tidy_dickens <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name)
# Graphs
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word Count")
# Graphs
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word =")
rm(list=ls())
gc()
rm(list=ls())
gc()
rm(list=ls())
gc()
rm(list=ls())
gc()
rm(list=ls())
gc()
rm(list=ls())
gc()
rm(list=ls())
gc()
rm(list=ls())
gc()
# Graphs
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word Count")
dickens_list <- read_csv('dickens_gutenberg.csv')
mirror <- 'http://gutenberg.readingroo.ms/'
book <- gutenberg_download(dickens_list$'Gutenberg ID'[1], mirror = mirror)
for(i in 2:nrow(dickens_list)) {
book <- book %>% add_row(gutenberg_download(dickens_list$`Gutenberg ID`[i],
mirror = mirror))
}
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID")) %>%
anti_join(stop_words)
total_words <- tidy_dickens %>% group_by(Name) %>% summarize(total=sum(n))
# Sentiment Analysis - Bing
bing_sentiments <- get_sentiments("bing")
tidy_dickens <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name)
# Graphs
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word Count")
# Contingency table
ct <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
# Chi-sq test
chSq <- chisq.test(ct)
View(bing_sentiments)
chSq
chSq$observed
# Contingency table
ct <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
# Chi-sq test
chSq <- chisq.test(ct)
View(ct)
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID"))
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID"))
total_words <- tidy_dickens %>% group_by(Name) %>% summarize(total=sum(n))
# Sentiment Analysis - Bing
bing_sentiments <- get_sentiments("bing")
tidy_dickens <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name)
# Graphs
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word Count")
# Contingency table
ct <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
# Graphs
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(Name, n, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Work",
y = "Word Count")
# Contingency table
ct <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
words_by_rank <- tidy_dickens %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
rm(list=ls())
gc()
# Load Libraries
library(tidyverse)
library(gutenbergr)
library(tidytext)
library(reshape2)
library(wordcloud)
dickens_list <- read_csv('dickens_gutenberg.csv')
mirror <- 'http://gutenberg.readingroo.ms/'
book <- gutenberg_download(dickens_list$`Gutenberg ID`[1],
mirror = mirror) %>% slice(dickens_list$start[1]:n())
for(i in 2:nrow(dickens_list)) {
book <- book %>% add_row(gutenberg_download(dickens_list$`Gutenberg ID`[i],
mirror = mirror) %>% slice(dickens_list$start[i]:n()))
}
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID"))
tidy_dickens_no_sw <- tidy_dickens %>% anti_join(stop_words)
total_words <- tidy_dickens %>% group_by(Name) %>% summarize(total=sum(n))
dickens_words <- left_join(tidy_dickens, total_words)
bing_sentiments <- get_sentiments("bing")
words_by_rank <- tidy_dickens %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
View(words_by_rank)
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = FALSE) + scale_x_log10() + scale_y_log10()
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = FALSE) + scale_x_log10() + scale_y_log10()
lm(log10(frequency) ~ log10(rank), data = words_by_rank)
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = FALSE) + scale_x_log10() + scale_y_log10()
lfit <- lm(log10(frequency) ~ log10(rank), data = words_by_rank)
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
lfit <- lm(log10(frequency) ~ log10(rank), data = words_by_rank)
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = FALSE) + scale_x_log10() + scale_y_log10() +
geom_abline(intercept = lfit$coefficients["(Intercept)"],
slope = lfit$coefficients["log10(rank)"])
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
lfit <- lm(log10(frequency) ~ log10(rank), data = words_by_rank)
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = FALSE) + scale_x_log10() + scale_y_log10() +
geom_abline(intercept = lfit$coefficients["(Intercept)"],
slope = lfit$coefficients["log10(rank)"])
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n)
View(dickens_tf_idf)
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
lfit <- lm(log10(frequency) ~ log10(rank), data = words_by_rank)
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = FALSE) + scale_x_log10() + scale_y_log10() +
geom_abline(intercept = lfit$coefficients["(Intercept)"],
slope = lfit$coefficients["log10(rank)"])
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n) %>%
arrange(desc(tf_idf))
View(dickens_tf_idf)
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
lfit <- lm(log10(frequency) ~ log10(rank), data = words_by_rank)
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = FALSE) + scale_x_log10() + scale_y_log10() +
geom_abline(intercept = lfit$coefficients["(Intercept)"],
slope = lfit$coefficients["log10(rank)"])
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n) %>%
arrange(desc(tf_idf))
dickens_tf_idf %>% group_by(Name) %>% slice_max(tf_idf, n = 10)
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
lfit <- lm(log10(frequency) ~ log10(rank), data = words_by_rank)
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = FALSE) + scale_x_log10() + scale_y_log10() +
geom_abline(intercept = lfit$coefficients["(Intercept)"],
slope = lfit$coefficients["log10(rank)"])
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n) %>%
arrange(desc(tf_idf))
dickens_tf_idf %>% group_by(Name) %>% slice_max(tf_idf, n = 10) %>%
ggplot(aes(tf_idf, word, fill=Name)) + geom_col(show.legend = FALSE) +
facet_wrap(~Name)
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
lfit <- lm(log10(frequency) ~ log10(rank), data = words_by_rank)
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = FALSE) + scale_x_log10() + scale_y_log10() +
geom_abline(intercept = lfit$coefficients["(Intercept)"],
slope = lfit$coefficients["log10(rank)"])
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n) %>%
arrange(desc(tf_idf))
dickens_tf_idf %>% group_by(Name) %>% slice_max(tf_idf, n = 10) %>%
ggplot(aes(tf_idf, word, fill=Name)) + geom_col(show.legend = FALSE) +
facet_wrap(~Name, scales = "free")
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
lfit <- lm(log10(frequency) ~ log10(rank), data = words_by_rank)
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = FALSE) + scale_x_log10() + scale_y_log10() +
geom_abline(intercept = lfit$coefficients["(Intercept)"],
slope = lfit$coefficients["log10(rank)"])
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n) %>%
arrange(desc(tf_idf))
dickens_tf_idf %>% group_by(Name) %>% slice_max(tf_idf, n = 10) %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill=Name)) +
geom_col(show.legend = FALSE) + facet_wrap(~Name, scales = "free")
tidy_dickens_no_sw %>% with(wordcloud(word, n, max.words=100))
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
lfit <- lm(log10(frequency) ~ log10(rank), data = words_by_rank)
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = FALSE) + scale_x_log10() + scale_y_log10() +
geom_abline(intercept = lfit$coefficients["(Intercept)"],
slope = lfit$coefficients["log10(rank)"])
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n) %>%
arrange(desc(tf_idf))
dickens_tf_idf %>% group_by(Name) %>% slice_max(tf_idf, n = 10) %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill=Name)) +
geom_col(show.legend = FALSE) + facet_wrap(~Name, scales = "free")
# Comment: This is undoubtedly drastic, but as far as I can tell, it works.
# Do let me know if I've made any errors.
for(i in 1:nrow(dickens_list)) {
gutenberg_download(dickens_list$`Gutenberg ID`[i],
mirror = mirror) %>% slice(dickens_list$start[i]:n()) %>%
unnest_tokens(word, text) %>% count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID")) %>%
anti_join(stop_words) %>% with(wordcloud(word, n, max.words=100))
}
knitr::opts_chunk$set(fig.height = FALSE, fig.width = FALSE, fig.align = FALSE)
# Comment: This is undoubtedly drastic, but as far as I can tell, it works.
# Do let me know if I've made any errors.
for(i in 1:nrow(dickens_list)) {
gutenberg_download(dickens_list$`Gutenberg ID`[i],
mirror = mirror) %>% slice(dickens_list$start[i]:n()) %>%
unnest_tokens(word, text) %>% count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID")) %>%
anti_join(stop_words) %>% with(wordcloud(word, n, max.words=100))
}
tinytex::reinstall_tinytex()
tidy_dickens_no_sw %>% with(wordcloud(word, n, max.words=100))
rm(list=ls())
gc()
# Load Libraries
library(tidyverse)
library(gutenbergr)
library(tidytext)
library(reshape2)
library(wordcloud)
dickens_list <- read_csv('dickens_gutenberg.csv')
mirror <- 'http://gutenberg.readingroo.ms/'
book <- gutenberg_download(dickens_list$`Gutenberg ID`[1],
mirror = mirror) %>% slice(dickens_list$start[1]:n())
for(i in 2:nrow(dickens_list)) {
book <- book %>% add_row(gutenberg_download(dickens_list$`Gutenberg ID`[i],
mirror = mirror) %>% slice(dickens_list$start[i]:n()))
}
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID"))
tidy_dickens_no_sw <- tidy_dickens %>% anti_join(stop_words)
total_words <- tidy_dickens %>% group_by(Name) %>% summarize(total=sum(n))
dickens_words <- left_join(tidy_dickens, total_words)
bing_sentiments <- get_sentiments("bing")
tidy_dickens <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name)
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(n, Name, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Word Count",
y = "Work, by Title")
ct <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
chSq <- chisq.test(ct)
chSq
chSq$observed
chSq$expected
chSq$stdres
afinn_sentiments <- get_sentiments("afinn")
tidy_dickens_afinn <- tidy_dickens %>%
inner_join(afinn_sentiments) %>% inner_join(bing_sentiments)
tidy_dickens_afinn %>% group_by(Name) %>%
summarize(value = mean(value))
tidy_dickens_afinn %>% ggplot(aes(Name, value)) + geom_violin()
new_ct <- tidy_dickens_afinn %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
knitr::opts_chunk$set(fig.height = 3.5, fig.width = 3, fig.align = FALSE)
new_ct <- tidy_dickens_afinn %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
chSq2 <- chisq.test(new_ct)
chSq2
chSq2$observed
chSq2$expected
chSq2$stdres
# Comment: This is undoubtedly drastic, but as far as I can tell, it works.
# Do let me know if I've made any errors.
for(i in 1:nrow(dickens_list)) {
gutenberg_download(dickens_list$`Gutenberg ID`[i],
mirror = mirror) %>% slice(dickens_list$start[i]:n()) %>%
unnest_tokens(word, text) %>% count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID")) %>%
anti_join(stop_words) %>% with(wordcloud(word, n, max.words=100))
}
knitr::opts_chunk$set(fig.height = FALSE, fig.width = FALSE, fig.align = FALSE)
tidy_dickens_no_sw %>% with(wordcloud(word, n, max.words=100))
tidy_dickens_no_sw %>% with(wordcloud(word, n, max.words=100))
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n) %>%
arrange(desc(tf_idf))
dickens_tf_idf %>% group_by(Name) %>% slice_max(tf_idf, n = 10) %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill=Name)) +
geom_col(show.legend = FALSE) + facet_wrap(~Name, scales = "free")
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n) %>%
arrange(desc(tf_idf))
dickens_tf_idf %>% group_by(Name) %>% slice_max(tf_idf, n = 10) %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill=Name)) +
geom_col(show.legend = FALSE) + facet_wrap(~Name, scales = "free")
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
lfit <- lm(log10(frequency) ~ log10(rank), data = words_by_rank)
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = FALSE) + scale_x_log10() + scale_y_log10() +
geom_abline(intercept = lfit$coefficients["(Intercept)"],
slope = lfit$coefficients["log10(rank)"])
View(dickens_words)
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n) %>%
arrange(desc(tf_idf))
dickens_tf_idf %>% group_by(Name) %>% slice_max(tf_idf, n = 10) %>%
ggplot(aes(n/total, fill=Name)) +
geom_col(show.legend = FALSE) + facet_wrap(~Name, scales = "free")
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n) %>%
arrange(desc(tf_idf))
dickens_tf_idf %>% group_by(Name) %>% slice_max(tf_idf, n = 10) %>%
ggplot(aes(n/total, fill=Name)) +
geom_col(show.legend = FALSE) + facet_wrap(~Name, scales = "free")
geom_col()
?geom_col
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n) %>%
arrange(desc(tf_idf))
dickens_tf_idf %>% group_by(Name) %>% slice_max(tf_idf, n = 10) %>%
ggplot(aes(n/total, fill=Name)) +
geom_histogram() + facet_wrap(~Name, ncol = 2)
#tf_idf, fct_reorder(word, tf_idf) + geom_col(show.legend = FALSE) + facet_wrap(~Name, scales = "free")
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n) %>%
arrange(desc(tf_idf))
dickens_tf_idf %>% group_by(Name) %>%
ggplot(aes(n/total, fill=Name)) +
geom_histogram() + facet_wrap(~Name, ncol = 2)
#tf_idf, fct_reorder(word, tf_idf) + geom_col(show.legend = FALSE) + facet_wrap(~Name, scales = "free")
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n) %>%
arrange(desc(tf_idf))
dickens_tf_idf %>% group_by(Name) %>% slice_max(tf_idf, n = 10) %>%
ggplot(aes(n/total, fill=Name)) +
geom_histogram() + facet_wrap(~Name, ncol = 2)
#tf_idf, fct_reorder(word, tf_idf) + geom_col(show.legend = FALSE) + facet_wrap(~Name, scales = "free")
dickens_tf_idf <- dickens_words %>% bind_tf_idf(word, Name, n) %>%
arrange(desc(tf_idf))
dickens_tf_idf %>% group_by(Name) %>% slice_max(tf_idf, n = 10) %>%
ggplot(aes(tf_idf, fct_reorder(word, tf_idf), fill=Name)) +
geom_col(show.legend = FALSE) + facet_wrap(~Name, scales = "free")
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
lfit <- lm(log10(frequency) ~ log10(rank), data = words_by_rank)
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = TRUE) + scale_x_log10() + scale_y_log10() +
geom_abline(intercept = lfit$coefficients["(Intercept)"],
slope = lfit$coefficients["log10(rank)"])
View(dickens_tf_idf)
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
lfit <- lm(log10(frequency) ~ log10(rank), data = words_by_rank)
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = TRUE) + scale_x_log10() + scale_y_log10() +
geom_abline(intercept = lfit$coefficients["(Intercept)"],
slope = lfit$coefficients["log10(rank)"])
rm(list=ls())
gc()
# Load Libraries
library(tidyverse)
library(gutenbergr)
library(tidytext)
library(reshape2)
library(wordcloud)
dickens_list <- read_csv('dickens_gutenberg.csv')
mirror <- 'http://gutenberg.readingroo.ms/'
book <- gutenberg_download(dickens_list$`Gutenberg ID`[1],
mirror = mirror) %>% slice(dickens_list$start[1]:n())
for(i in 2:nrow(dickens_list)) {
book <- book %>% add_row(gutenberg_download(dickens_list$`Gutenberg ID`[i],
mirror = mirror) %>% slice(dickens_list$start[i]:n()))
}
tidy_dickens <- book %>% unnest_tokens(word, text) %>%
count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID"))
tidy_dickens_no_sw <- tidy_dickens %>% anti_join(stop_words)
total_words <- tidy_dickens %>% group_by(Name) %>% summarize(total=sum(n))
dickens_words <- left_join(tidy_dickens, total_words)
bing_sentiments <- get_sentiments("bing")
tidy_dickens <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name)
tidy_dickens %>%
count(sentiment) %>% ggplot(aes(n, Name, fill=sentiment)) +
geom_col(position='dodge')  +
labs(title="Dickens Sentiment Distributions - Bing Lexicon",
x = "Word Count",
y = "Work, by Title")
ct <- tidy_dickens %>% inner_join(bing_sentiments) %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
chSq <- chisq.test(ct)
chSq
chSq$observed
chSq$expected
chSq$stdres
afinn_sentiments <- get_sentiments("afinn")
tidy_dickens_afinn <- tidy_dickens %>%
inner_join(afinn_sentiments) %>% inner_join(bing_sentiments)
tidy_dickens_afinn %>% group_by(Name) %>%
summarize(value = mean(value))
tidy_dickens_afinn %>% ggplot(aes(Name, value)) + geom_violin()
new_ct <- tidy_dickens_afinn %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
knitr::opts_chunk$set(fig.height = 3.5, fig.width = 3, fig.align = FALSE)
new_ct <- tidy_dickens_afinn %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
chSq2 <- chisq.test(new_ct)
chSq2
chSq2$observed
chSq2$expected
chSq2$stdres
# Comment: This is undoubtedly drastic, but as far as I can tell, it works.
# Do let me know if I've made any errors.
for(i in 1:nrow(dickens_list)) {
gutenberg_download(dickens_list$`Gutenberg ID`[i],
mirror = mirror) %>% slice(dickens_list$start[i]:n()) %>%
unnest_tokens(word, text) %>% count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID")) %>%
anti_join(stop_words) %>% with(wordcloud(word, n, max.words=100),
scale=c(3.5,0.25))
}
knitr::opts_chunk$set(fig.height = FALSE, fig.width = FALSE, fig.align = FALSE)
tidy_dickens_no_sw %>% with(wordcloud(word, n, max.words=100))
knitr::opts_chunk$set(fig.height = 4, fig.width = FALSE, fig.align = FALSE)
words_by_rank <- dickens_words %>% group_by(Name) %>%
mutate(rank = row_number(), frequency = n/total) %>% ungroup()
lfit <- lm(log10(frequency) ~ log10(rank), data = words_by_rank)
words_by_rank %>% ggplot(aes(rank, frequency, color = Name)) +
geom_line(show.legend = TRUE) + scale_x_log10() + scale_y_log10() +
geom_abline(intercept = lfit$coefficients["(Intercept)"],
slope = lfit$coefficients["log10(rank)"])
tidy_dickens_afinn <- tidy_dickens %>%
inner_join(afinn_sentiments) %>% inner_join(bing_sentiments)
tidy_dickens_afinn %>% group_by(Name) %>%
summarize(value = mean(value))
tidy_dickens_afinn %>% ggplot(aes(Name, value)) + geom_violin()
new_ct <- tidy_dickens_afinn %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
tidy_dickens_afinn <- tidy_dickens %>%
inner_join(afinn_sentiments) %>% inner_join(bing_sentiments)
tidy_dickens_afinn %>% group_by(Name) %>%
summarize(value = mean(value))
tidy_dickens_afinn %>% ggplot(aes(Name, value)) + geom_violin()
new_ct <- tidy_dickens_afinn %>% group_by(Name) %>%
count(sentiment) %>% pivot_wider(names_from = sentiment, values_from = n) %>%
column_to_rownames(var = "Name")
# Comment: This is undoubtedly drastic, but as far as I can tell, it works.
# Do let me know if I've made any errors.
for(i in 1:nrow(dickens_list)) {
print(dickens_list$Name[i])
gutenberg_download(dickens_list$`Gutenberg ID`[i],
mirror = mirror) %>% slice(dickens_list$start[i]:n()) %>%
unnest_tokens(word, text) %>% count(gutenberg_id, word, sort = TRUE) %>%
inner_join(dickens_list, by = c(gutenberg_id = "Gutenberg ID")) %>%
anti_join(stop_words) %>% with(wordcloud(word, n, max.words=100),
scale=c(3.5,0.25))
}
# Comment: This is undoubtedly drastic, but as far as I can tell, it works.
# Do let me know if I've made any errors.
for(i in 1:nrow(dickens_list)) {
\pagebreak
knitr::opts_chunk$set(fig.height = 4, fig.width = FALSE, fig.align = "center")
